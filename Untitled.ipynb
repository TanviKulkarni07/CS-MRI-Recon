{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../../common/')\n",
    "sys.path.insert(0,'/home/ubuntu/Downloads/mri_recon/robustness-CS/bart-0.5.00/python/')\n",
    "import bart\n",
    "\n",
    "import subsample\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "from common import utils\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "try:\n",
    "    import nibabel as nib\n",
    "except:\n",
    "    ! pip install nibabel \n",
    "    import nibabel as nib\n",
    "\n",
    "from data import transforms, mri_data\n",
    "\n",
    "class SliceData(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset that provides access to MR image slices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root,challenge, sample_rate=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (pathlib.Path): Path to the dataset.\n",
    "            transform (callable): A callable object that pre-processes the raw data into\n",
    "                appropriate form. The transform function should take 'kspace', 'target',\n",
    "                'attributes', 'filename', and 'slice' as inputs. 'target' may be null\n",
    "                for test data.\n",
    "            challenge (str): \"singlecoil\" or \"multicoil\" depending on which challenge to use.\n",
    "            sample_rate (float, optional): A float between 0 and 1. This controls what fraction\n",
    "                of the volumes should be loaded.\n",
    "        \"\"\"\n",
    "        self.mask_func = subsample.RandomMaskFunc(center_fractions=[0.08, 0.04], accelerations=[4, 8])\n",
    "        \n",
    "        if challenge not in ('singlecoil', 'multicoil'):\n",
    "            raise ValueError('challenge should be either \"singlecoil\" or \"multicoil\"')\n",
    "\n",
    "        #self.transform = transform\n",
    "        self.recons_key = 'reconstruction_esc' if challenge == 'singlecoil' \\\n",
    "            else 'reconstruction_rss'\n",
    "\n",
    "        self.examples = []\n",
    "        files = list(pathlib.Path(root).iterdir())\n",
    "        if sample_rate < 1:\n",
    "            random.shuffle(files)\n",
    "            num_files = round(len(files) * sample_rate)\n",
    "            files = files[:num_files]\n",
    "        for fname in sorted(files):\n",
    "            \n",
    "            img = nib.load(fname)\n",
    "            img_data = img.get_data()\n",
    "            img_data_arr = np.asarray(img_data)\n",
    "            img_data_arr = img_data_arr.astype(np.float32)\n",
    "            img_data_torch = torch.from_numpy(img_data_arr)\n",
    "            kspace = np.zeros(img_data_torch.shape,dtype='complex')\n",
    "            kspace = torch.from_numpy(kspace)\n",
    "            for i in range(img_data_torch.shape[2]):\n",
    "                fft_img = torch.fft.fft2(img_data_torch[:,:,i],norm=\"ortho\")\n",
    "                kspace[:,:,i] = torch.fft.fftshift(fft_img ) \n",
    "            #kspace = h5py.File(fname, 'r')['kspace']\n",
    "            num_slices = kspace.shape[2]\n",
    "            self.masked_kspace, _ = transforms.apply_mask(kspace, self.mask_func)\n",
    "            self.examples += [(self.masked_kspace[:,:,slice],fname, slice) for slice in range(num_slices)]\n",
    "    ''''\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        masked_kspace,fname, slice = self.examples[i]\n",
    "        with h5py.File(fname, 'r') as data:\n",
    "            kspace = data['kspace'][slice]\n",
    "            target = data[self.recons_key][slice] if self.recons_key in data else None\n",
    "            return self.transform(kspace, target, data.attrs, fname.name, slice)\n",
    "        \n",
    "    '''\n",
    "    def __getlist__(self):\n",
    "        return self.examples\n",
    "    def __getmaskedkspace__(self):\n",
    "        return self.masked_kspace\n",
    "\n",
    "def save_reconstructions(reconstructions, out_dir):\n",
    "    \"\"\"\n",
    "    Saves the reconstructions from a model into h5 files that is appropriate for submission\n",
    "    to the leaderboard.\n",
    "\n",
    "    Args:\n",
    "        reconstructions (dict[str, np.array]): A dictionary mapping input filenames to\n",
    "            corresponding reconstructions (of shape num_slices x height x width).\n",
    "        out_dir (pathlib.Path): Path to the output directory where the reconstructions\n",
    "            should be saved.\n",
    "    \"\"\"\n",
    "    for fname, recons in reconstructions.items():\n",
    "        with h5py.File(out_dir + fname, 'w') as f:\n",
    "            f.create_dataset('reconstruction', data=recons)\n",
    "            \n",
    "def save_outputs(outputs, output_path):\n",
    "    reconstructions = defaultdict(list)\n",
    "    for fname, slice, pred in outputs:\n",
    "        reconstructions[fname].append((slice, pred))\n",
    "    reconstructions = {\n",
    "        fname: np.stack([pred for _, pred in sorted(slice_preds)])\n",
    "        for fname, slice_preds in reconstructions.items()\n",
    "    }\n",
    "    save_reconstructions(reconstructions, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/p36env/lib/python3.6/site-packages/ipykernel_launcher.py:69: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    }
   ],
   "source": [
    "s = SliceData('/home/ubuntu/Downloads/dataset/', 'singlecoil')\n",
    "data = (s.__getlist__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_kspace = s.__getmaskedkspace__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 256, 176])\n",
      "torch.Size([1, 176, 1, 256, 256])\n",
      "torch.Size([176, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "masked_kspace.shape\n",
    "masked_kspace_cd = masked_kspace.unsqueeze(0)\n",
    "print(masked_kspace_cd.shape)\n",
    "masked_kspace_cd = masked_kspace_cd.permute(3,0, 1, 2).unsqueeze(0)\n",
    "print(masked_kspace_cd.shape)\n",
    "masked_kspace_cd = masked_kspace_cd.squeeze(0)\n",
    "print(masked_kspace_cd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import RMSprop\n",
    "\n",
    "from common.args import Args\n",
    "from common.subsample import create_mask_for_mask_type\n",
    "from data import transforms\n",
    "#from mri_model import MRIModel\n",
    "from unet_model import UnetModel\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   min_delta=0.00,\n",
    "   patience=3,\n",
    "   verbose=False,\n",
    "   mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mri_model import MRIModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnetMRIModel(MRIModel):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        self.unet = UnetModel(\n",
    "            in_chans=1,\n",
    "            out_chans=1,\n",
    "            chans=hparams.num_chans,\n",
    "            num_pool_layers=hparams.num_pools,\n",
    "            drop_prob=hparams.drop_prob\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.unet(input.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input, target, mean, std, _, _ = batch\n",
    "        output = self.forward(input)\n",
    "        loss = F.l1_loss(output, target)\n",
    "        logs = {'loss': loss.item()}\n",
    "        return dict(loss=loss, log=logs)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input, target, mean, std, fname, slice = batch\n",
    "        output = self.forward(input)\n",
    "        mean = mean.unsqueeze(1).unsqueeze(2)\n",
    "        std = std.unsqueeze(1).unsqueeze(2)\n",
    "        return {\n",
    "            'fname': fname,\n",
    "            'slice': slice,\n",
    "            'output': (output * std + mean).cpu().numpy(),\n",
    "            'target': (target * std + mean).cpu().numpy(),\n",
    "            'val_loss': F.l1_loss(output, target),\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input, _, mean, std, fname, slice = batch\n",
    "        output = self.forward(input)\n",
    "        mean = mean.unsqueeze(1).unsqueeze(2)\n",
    "        std = std.unsqueeze(1).unsqueeze(2)\n",
    "        return {\n",
    "            'fname': fname,\n",
    "            'slice': slice,\n",
    "            'output': (output * std + mean).cpu().numpy(),\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = RMSprop(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optim, self.hparams.lr_step_size, self.hparams.lr_gamma)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "    def train_data_transform(self):\n",
    "        mask = create_mask_for_mask_type(self.hparams.mask_type, self.hparams.center_fractions,\n",
    "                                         self.hparams.accelerations)\n",
    "        return DataTransform(self.hparams.resolution, self.hparams.challenge, mask, use_seed=False)\n",
    "\n",
    "    def val_data_transform(self):\n",
    "        mask = create_mask_for_mask_type(self.hparams.mask_type, self.hparams.center_fractions,\n",
    "                                         self.hparams.accelerations)\n",
    "        return DataTransform(self.hparams.resolution, self.hparams.challenge, mask)\n",
    "\n",
    "    def test_data_transform(self):\n",
    "        return DataTransform(self.hparams.resolution, self.hparams.challenge)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parser):\n",
    "        parser.add_argument('--num-pools', type=int, default=4, help='Number of U-Net pooling layers')\n",
    "        parser.add_argument('--drop-prob', type=float, default=0.0, help='Dropout probability')\n",
    "        parser.add_argument('--num-chans', type=int, default=32, help='Number of U-Net channels')\n",
    "        parser.add_argument('--batch-size', default=16, type=int, help='Mini batch size')\n",
    "        parser.add_argument('--lr', type=float, default=0.001, help='Learning rate')\n",
    "        parser.add_argument('--lr-step-size', type=int, default=40,\n",
    "                            help='Period of learning rate decay')\n",
    "        parser.add_argument('--lr-gamma', type=float, default=0.1,\n",
    "                            help='Multiplicative factor of learning rate decay')\n",
    "        parser.add_argument('--weight-decay', type=float, default=0.,\n",
    "                            help='Strength of weight decay regularization')\n",
    "        parser.add_argument('--mask_type',default='random')\n",
    "        return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self,mode,challenge,exp_dir,exp,mask_type,num_epochs,gpus,action='store_true'):\n",
    "        self.mode=mode\n",
    "        self.num_epochs=num_epochs\n",
    "        self.gpus=gpus\n",
    "        self.exp = exp\n",
    "        self.exp_dir=exp_dir\n",
    "        self.seed = 42\n",
    "        self.challenge = challenge\n",
    "        self.mask_type = mask_type\n",
    "args = Args('train','singlecoil','/home/ubuntu/Downloads/dataset/','unet','equispaced',50,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(args, logger):\n",
    "    return Trainer(\n",
    "        #num_nodes=1,\n",
    "        logger=logger,\n",
    "        default_root_dir=args.exp_dir,\n",
    "        checkpoint_callback=True,\n",
    "        max_epochs=args.num_epochs,\n",
    "        gpus=args.gpus,\n",
    "        distributed_backend='ddp',\n",
    "        check_val_every_n_epoch=1,\n",
    "        val_check_interval=1.,\n",
    "        callbacks=[early_stop_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/p36env/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: You requested distributed training on GPUs, but none is available, so we set backend to `ddp_cpu`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/p36env/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: You are running on single node with no parallelization, so distributed has no effect.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "load_version = None\n",
    "logger = TestTubeLogger(save_dir=args.exp_dir, name=args.exp, version=load_version)\n",
    "trainer = create_trainer(args, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hparams():\n",
    "    def __init__(self,in_chans, out_chans, num_chans, num_pools, drop_prob):\n",
    "        self.num_chans= num_chans\n",
    "        self.num_pools = num_pools\n",
    "        self.drop_prob= drop_prob\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "hparams1 = hparams(1,1,32,4,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetModel(\n",
    "            in_chans=1,\n",
    "            out_chans=1,\n",
    "            chans=hparams1.num_chans,\n",
    "            num_pool_layers=hparams1.num_pools,\n",
    "            drop_prob=hparams1.drop_prob\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Byte but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f2ef4be71813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/mri_recon/robustness-CS/DIP_UNET_models/unet_and_tv/unet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Apply down-sampling layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_sample_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/mri_recon/robustness-CS/DIP_UNET_models/unet_and_tv/unet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_chans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36env/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p36env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Byte but found Float"
     ]
    }
   ],
   "source": [
    "target = model.forward(m_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_kspace_cd = torch.abs(masked_kspace_cd).type(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 320, 176])\n",
      "torch.Size([1, 176, 1, 320, 320])\n",
      "torch.Size([176, 1, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "m = np.ones((320,320,176),dtype=np.uint8)\n",
    "m_tensor = torch.from_numpy(m)\n",
    "m_tensor = m_tensor.unsqueeze(0)\n",
    "print(m_tensor.shape)\n",
    "m_tensor= m_tensor.permute(3,0, 1, 2).unsqueeze(0)\n",
    "print(m_tensor.shape)\n",
    "m_tensor= m_tensor.squeeze(0)\n",
    "print(m_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
